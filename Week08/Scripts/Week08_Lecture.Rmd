---
title: "Week 8 Lecture"
author: "Kassandra Jensen"
date: "2024-10-15"
output: 
  html_document:
    toc: TRUE
    toc_float: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## packages
```{r}
library(here)
library(tidyverse)
library(tidytext)
library(wordcloud2)
library(janeaustenr)
```
```{r}
words<-"This is a string"
words

#You can also have several strings in a vector.
words_vector<-c("Apples", "Bananas","Oranges")
words_vector
```
# Manipulation
```{r}
#Combine
paste("High temp", "Low pH")

# Can say how you want it separated
paste("High temp", "Low pH", sep= "-")

# No space at all in between
paste0("High temp", "Low pH")
```
### Working with vectors
```{r}
shapes <- c("Square", "Circle", "Triangle")
paste ("My favorite shape is a", shapes)

two_cities <- c("best", "worst")
paste("It was the", two_cities, "of times.")
```
### Individual characters
```{r}
str_length(shapes) ## Give you how many letters are in word 
## Maybe good for bioinformatics - know how long basepairs are

## extract specific characters
seq_data<-c("ATCCCGTC")
str_sub(seq_data, start = 2, end = 4)
```
### Modify strings
```{r}
str_sub(seq_data, start = 3, end = 3) <- "A" # add an A in the 3rd position
seq_data

## duplicate patterns in your strings
str_dup(seq_data, times = c(2, 3)) # times is the number of times to duplicate each string
```

# White Space
Say you have a column and you did not copy and paste your treatments like you learned in the first week of class. You now have some words with extra white spaces and R thinks its an entirely new word.
```{r}
badtreatments<-c("High", " High", "High ", "Low", "Low")
badtreatments

str_trim(badtreatments)

str_trim(badtreatments, side = "left") # this removes left

## You can just put the column name in here - I don't think you need to have the vector written out

# The opposite of str_trim is str_pad, to add white space to either side
str_pad(badtreatments, 5, side = "right") # add a white space to the right side after the 5th character

str_pad(badtreatments, 5, side = "right", pad = "1") # add a 1 to the right side after the 5th character

```

# Locale Sensitive
Default is english.
```{r}
## THIS IS SO HELFUL
x<-"I love R!"

#Make everything upper case
str_to_upper(x)

#Make everything lower case
str_to_lower(x)

#Make title case (capitalize first letter of each word)
str_to_title(x)
```

# Pattern matching
{stringr} has functions to view, detect, locate, extract, match, replace, and split strings based on specific patterns.
```{r}
data<-c("AAA", "TATA", "CTAG", "GCTT")

# find all the strings with an A
str_view(data, pattern = "A")


# Detect a specific pattern
str_detect(data, pattern = "A")
str_detect(data, pattern = "AT")

## Locate a pattern
str_locate(data, pattern = "AT")
## Shows you that the second one is the only one that had it and it starts at the 2nd character and ends at the 3rd character
```

# Regular Expressions
### Metacharacters
```{r}
vals<-c("a.b", "b.c","c.d")
str_replace(vals, "\\.", " ")
## replaces the period (need to use the slashes bc . already has a function in R) with space


vals<-c("a.b.c", "b.c.d","c.d.e")
#string, pattern, replace
str_replace(vals, "\\.", " ")

#str_replace only replaces the first instance. Let's try str_replace_all()
#string, pattern, replace
str_replace_all(vals, "\\.", " ")
```

### Sequences
Sequences of characters which can match. 
There is a table with the shorthand/ "anchors" commonly used in R
```{r}
## Only keep values that ONLY have digits in it
val2<-c("test 123", "test 456", "test")
str_subset(val2, "\\d")
```

### Character class
```{r}
# Match any one lower case vowel
str_count(val2, "[aeiou]")

# count any digit
str_count(val2, "[0-9]")
```

### Quantifiers
```{r}
strings<-c("550-153-7578",
         "banana",
         "435.114.7586",
         "home: 672-442-6739")

#Make a regex that finds all the strings that contain a phone number. We know there is a specific pattern (3 numbers, 3 numbers, 4 numbers and it can have either a "." or "-" to separate them). Let's also say we know that the first number cannot be a 1

phone <- "([2-9][0-9]{2})[- .]([0-9]{3})[- .]([0-9]{4})"

## breakdown of phone
# ([2-9] = find any digit between 2 -9
# [0-9]{2} = find any digit 0-9, them do that twice
# [- .] = find a dash or dot
# [0-9]{3}) = find number 0-9, do that three times
# [- .] = find a dash or dot
# [0-9]{4} = find number 0-9, do that four times


str_detect(strings, phone) # get rid of banana
# subset only the strings with phone numbers
test<-str_subset(strings, phone)
test

### Think, pair, share

### Let's clean it up. Lets replace all the "." with "-" and extract only the numbers (leaving the letters behind). Remove any extra white space. You can use a sequence of pipes.

test_test <- str_replace_all(test, "home:", " ") 
test_test1 <- str_subset(test_test, "[0123456789]") 
test_test2 <-  str_replace_all(test_test, "\\.", "-")
str_trim(test_test2)

## a better way
test %>%
  str_replace_all(pattern = "\\.", replacement = "-") %>% # replace periods with -
  str_replace_all(pattern = "[a-zA-Z]|\\:", replacement = "") %>% # remove all the things we don't want
  str_trim() # trim the white space


## [a-zA-Z]|\\: => that line that goes straight up and down means 'or' and so its, any letters, OR something with a colon
```
# Tidytext
```{r}
# explore it
head(austen_books())
tail(austen_books())

## Let's clean it up and add a column for line and chapter
original_books <- austen_books() %>% # get all of Jane Austen's books
  group_by(book) %>%
  mutate(line = row_number(), # find every line
         chapter = cumsum(str_detect(text, regex("^chapter [\\divxlc]", # count the chapters (starts with the word chapter followed by a digit or roman numeral- divxlc - digits, then the rest are roman numerals)
                                                 ignore_case = TRUE)))) %>% #ignore lower or uppercase
  ungroup() # ungroup it so we have a dataframe again
# don't try to view the entire thing... its >73000 lines...
head(original_books)
tail(original_books)


### Because we are interest in text mining, we will want to clean this so that there is only one word per row so its tidy. In tidytext each word is refered to as a token. The function to unnest the data so that its only one word per row is unnest_tokens().

tidy_books <- original_books %>%
  unnest_tokens(output = word, input = text) # add a column named word, with the input as the text column
head(tidy_books) # there are now >725,000 rows. Don't view the entire thing!
tail(tidy_books)

## Filter stopwords
cleaned_books <- tidy_books %>%
  anti_join(get_stopwords()) # dataframe without the stopwords
## anti_join => Anti joins are a type of filtering join, since they return the contents of the first table, but with their rows filtered depending upon the match conditions

head(cleaned_books)
tail(cleaned_books)

## What is most used word in all of her books?
cleaned_books %>%
#  group_by(book) %>% # can group by book or chapter or whatever
  count(word, sort = TRUE) 


## sentiment analysis
# how many positive and negative words
sent_word_counts <- tidy_books %>%
  inner_join(get_sentiments()) %>% # only keep pos or negative words ## i think this is it's own data set that it joins by 
  count(word, sentiment, sort = TRUE) # count them
head(sent_word_counts)[1:3,]
## not super accurate bc it thinks its to miss = long for not Miss. 

## We can now use ggplot to visualize counts of positive and negative words in the books
sent_word_counts %>%
  filter(n > 150) %>% # take only if there are over 150 instances of it
  mutate(n = ifelse(sentiment == "negative", -n, n)) %>% # add a column where if the word is negative make the count negative
  mutate(word = reorder(word, n)) %>% # sort it so it gows from largest to smallest
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col() +
  coord_flip() +
  labs(y = "Contribution to sentiment")


### Make a word clour
#Use the {wordcloud} package to make an interactive word cloud

words<-cleaned_books %>%
  count(word) %>% # count all the words
  arrange(desc(n))%>% # sort the words
  slice(1:100) #take the top 100
wordcloud2(words, shape = 'triangle', size=0.3) # make a wordcloud out of the top 100 words
```
```{r}
### Today's totally awesome r package --> look at slide but you can turn your ggplots into a postcard and send to someone.
## Called ggirl - gg in real life lol
```






